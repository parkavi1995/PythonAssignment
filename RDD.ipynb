{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmYPlzvxPsw+R6t78flpJ6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkavi1995/PythonAssignment/blob/main/RDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWaSiJlqEBfT"
      },
      "outputs": [],
      "source": [
        "{\n",
        "  \"nbformat\": 4,\n",
        "  \"nbformat_minor\": 0,\n",
        "  \"metadata\": {\n",
        "    \"colab\": {\n",
        "      \"provenance\": []\n",
        "    },\n",
        "    \"kernelspec\": {\n",
        "      \"name\": \"python3\",\n",
        "      \"display_name\": \"Python 3\"\n",
        "    },\n",
        "    \"language_info\": {\n",
        "      \"name\": \"python\"\n",
        "    }\n",
        "  },\n",
        "  \"cells\": [\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"import os\\n\",\n",
        "        \"os.environ[\\\"SPARK_HOME\\\"] = \\\"/content/spark-3.0.0-bin-hadoop2.7\\\"\\n\",\n",
        "        \"import findspark\\n\",\n",
        "        \"findspark.init()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"id\": \"KCgmpsXOwun7\"\n",
        "      },\n",
        "      \"execution_count\": 2,\n",
        "      \"outputs\": []\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"from pyspark.sql import SparkSession\\n\",\n",
        "        \"spark = SparkSession.builder.master(\\\"local\\\").appName(\\\"RDD\\\").getOrCreate()\\n\",\n",
        "        \"sc = spark.sparkContext\\n\",\n",
        "        \"\\n\",\n",
        "        \"data = [\\\"C\\\", \\\"Programming\\\", \\\"C++\\\", \\\"Java\\\", \\\"Scala\\\", \\\"Python\\\"]\\n\",\n",
        "        \"rdd = sc.parallelize(data)\\n\",\n",
        "        \"\\n\",\n",
        "        \"filtered_rdd = rdd.filter(lambda x: len(x) > 5)\\n\",\n",
        "        \"filtered_elements = filtered_rdd.collect()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Print the filtered elements\\n\",\n",
        "        \"for element in filtered_elements:\\n\",\n",
        "        \"    print(element)\\n\",\n",
        "        \"\\n\",\n",
        "        \"for element in reversed(filtered_elements):\\n\",\n",
        "        \"    print(element)\\n\",\n",
        "        \"\\n\",\n",
        "        \"sc.stop()\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"ryFfwozjw1Um\",\n",
        "        \"outputId\": \"91f5887d-2672-44d0-9645-6144684393e7\"\n",
        "      },\n",
        "      \"execution_count\": 8,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Programming\\n\",\n",
        "            \"Python\\n\",\n",
        "            \"Python\\n\",\n",
        "            \"Programming\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"cell_type\": \"code\",\n",
        "      \"source\": [\n",
        "        \"from pyspark.sql import SparkSession\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Initialize Spark session\\n\",\n",
        "        \"spark = SparkSession.builder.appName(\\\"RDDTransformation\\\").getOrCreate()\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Generate an RDD of multiples of 1024 (kilobytes)\\n\",\n",
        "        \"kilobytes_rdd = spark.sparkContext.parallelize(range(1, 20)).map(lambda x: x * 1024)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Convert each element to its respective MB\\n\",\n",
        "        \"megabytes_rdd = kilobytes_rdd.map(lambda x: x / 1024.0)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Filter elements greater than 10 MB\\n\",\n",
        "        \"filtered_rdd = megabytes_rdd.filter(lambda x: x > 10)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Apply transformation to convert MB to GB\\n\",\n",
        "        \"gigabytes_rdd = filtered_rdd.map(lambda x: x / 1024.0)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Print results\\n\",\n",
        "        \"print(\\\"Megabytes:\\\")\\n\",\n",
        "        \"for element in megabytes_rdd.collect():\\n\",\n",
        "        \"  print(element)\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"Filtered elements (greater than 10 MB):\\\")\\n\",\n",
        "        \"for element in filtered_rdd.collect():\\n\",\n",
        "        \"  print(element)\\n\",\n",
        "        \"\\n\",\n",
        "        \"print(\\\"Gigabytes:\\\")\\n\",\n",
        "        \"for element in gigabytes_rdd.collect():\\n\",\n",
        "        \"  print(element)\\n\",\n",
        "        \"\\n\",\n",
        "        \"# Stop the Spark session\\n\",\n",
        "        \"spark.stop()\\n\"\n",
        "      ],\n",
        "      \"metadata\": {\n",
        "        \"colab\": {\n",
        "          \"base_uri\": \"https://localhost:8080/\"\n",
        "        },\n",
        "        \"id\": \"DxL8oZvrw7_F\",\n",
        "        \"outputId\": \"c78f3dcc-0069-4800-b7e2-c35d781711d6\"\n",
        "      },\n",
        "      \"execution_count\": 7,\n",
        "      \"outputs\": [\n",
        "        {\n",
        "          \"output_type\": \"stream\",\n",
        "          \"name\": \"stdout\",\n",
        "          \"text\": [\n",
        "            \"Megabytes:\\n\",\n",
        "            \"1.0\\n\",\n",
        "            \"2.0\\n\",\n",
        "            \"3.0\\n\",\n",
        "            \"4.0\\n\",\n",
        "            \"5.0\\n\",\n",
        "            \"6.0\\n\",\n",
        "            \"7.0\\n\",\n",
        "            \"8.0\\n\",\n",
        "            \"9.0\\n\",\n",
        "            \"10.0\\n\",\n",
        "            \"11.0\\n\",\n",
        "            \"12.0\\n\",\n",
        "            \"13.0\\n\",\n",
        "            \"14.0\\n\",\n",
        "            \"15.0\\n\",\n",
        "            \"16.0\\n\",\n",
        "            \"17.0\\n\",\n",
        "            \"18.0\\n\",\n",
        "            \"19.0\\n\",\n",
        "            \"Filtered elements (greater than 10 MB):\\n\",\n",
        "            \"11.0\\n\",\n",
        "            \"12.0\\n\",\n",
        "            \"13.0\\n\",\n",
        "            \"14.0\\n\",\n",
        "            \"15.0\\n\",\n",
        "            \"16.0\\n\",\n",
        "            \"17.0\\n\",\n",
        "            \"18.0\\n\",\n",
        "            \"19.0\\n\",\n",
        "            \"Gigabytes:\\n\",\n",
        "            \"0.0107421875\\n\",\n",
        "            \"0.01171875\\n\",\n",
        "            \"0.0126953125\\n\",\n",
        "            \"0.013671875\\n\",\n",
        "            \"0.0146484375\\n\",\n",
        "            \"0.015625\\n\",\n",
        "            \"0.0166015625\\n\",\n",
        "            \"0.017578125\\n\",\n",
        "            \"0.0185546875\\n\"\n",
        "          ]\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "  ]\n",
        "}\n"
      ]
    }
  ]
}